{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning with Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "1. **Loading** Boston dataset\n",
    "2. Splitting into **train**- and **test**-set\n",
    "3. Creating a **model** and training it\n",
    "4. **Predicting** test set\n",
    "5. **Evaluating** the result\n",
    "6. Using **other models**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will explain how to make a regression analysis to predict features of our data. We will use a linear regression because the concept is easy to understand. The dataset we will use is the Boston-dataset from ScikitLearn.\n",
    "\n",
    "A regression analysis tries to fit a model to a certain dataset, just like classification did. However, classification tries to match a specific set of labels with the data. Regression allows us to predict continuous values, like numbers, even if we haven't seen an entry in the data with that number before.\n",
    "\n",
    "To start, we do some Python imports..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import datasets, linear_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading Boston dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the dataset from the datasets module in sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = datasets.load_boston()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains a \"data\" and a \"target\" element. The \"data\"-element contains the features. The \"target\"-element contains the values we want to predict for each row in the data.\n",
    "We can check the dimensions of these arrays to see how many rows and features there are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data is an (506, 13) array.\n",
      "Target is an (506,) array.\n"
     ]
    }
   ],
   "source": [
    "print(\"Data is an \" + str(boston.data.shape) + \" array.\")\n",
    "print(\"Target is an \" + str(boston.target.shape) + \" array.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can print the description of the dataset, to gain information about the data in the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _boston_dataset:\n",
      "\n",
      "Boston house prices dataset\n",
      "---------------------------\n",
      "\n",
      "**Data Set Characteristics:**  \n",
      "\n",
      "    :Number of Instances: 506 \n",
      "\n",
      "    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\n",
      "\n",
      "    :Attribute Information (in order):\n",
      "        - CRIM     per capita crime rate by town\n",
      "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
      "        - INDUS    proportion of non-retail business acres per town\n",
      "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
      "        - NOX      nitric oxides concentration (parts per 10 million)\n",
      "        - RM       average number of rooms per dwelling\n",
      "        - AGE      proportion of owner-occupied units built prior to 1940\n",
      "        - DIS      weighted distances to five Boston employment centres\n",
      "        - RAD      index of accessibility to radial highways\n",
      "        - TAX      full-value property-tax rate per $10,000\n",
      "        - PTRATIO  pupil-teacher ratio by town\n",
      "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
      "        - LSTAT    % lower status of the population\n",
      "        - MEDV     Median value of owner-occupied homes in $1000's\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
      "\n",
      "This is a copy of UCI ML housing dataset.\n",
      "https://archive.ics.uci.edu/ml/machine-learning-databases/housing/\n",
      "\n",
      "\n",
      "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
      "\n",
      "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
      "prices and the demand for clean air', J. Environ. Economics & Management,\n",
      "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
      "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
      "pages 244-261 of the latter.\n",
      "\n",
      "The Boston house-price data has been used in many machine learning papers that address regression\n",
      "problems.   \n",
      "     \n",
      ".. topic:: References\n",
      "\n",
      "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
      "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(boston.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our Boston-dataset contains information about houses in Boston. Every house has a number of features, like the number of rooms or the crime rate in the town. Our goal is to predict the house's price from these features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Splitting into train- and test-set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We must prepare the data before we can use it in an algorithm. We must turn our data- and target-array into a train_X, train_y, test_X and test_y set. To do this, we will write a function that we can use througout the notebook. We could also use sklearn's function for this, like we did in the previous notebook. But to get a better understanding of what happens, we will do it ourselves.\n",
    "\n",
    "Write a function that:\n",
    "* Takes `data`, `target` and `splitsize=20` as parameters.\n",
    "* Splits the data into `X_train` and `X_test`.\n",
    "* Splits the target into `y_train` and `y_test`.\n",
    "\n",
    "Hint: In Python, you can select the last 5 elements from an array like this: `a[-5:]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test(data,target,splitsize=20):\n",
    "    # TODO: complete this function\n",
    "        \n",
    "    X_train = data[:-splitsize,:] # currently, this selects all rows and all columns\n",
    "    X_test  = data[-splitsize:,:]\n",
    "    \n",
    "    y_train = target[:-splitsize] # currently, this selects all rows\n",
    "    y_test  = target[-splitsize:]\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then call this function on the data and print the shape to confirm we split it the right way.\n",
    "\n",
    "The shapes should be `(486, 13)`, `(486,)`, `(20, 13)` and `(20,)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (486, 13), y_train shape: (486,)\n",
      "X_test  shape: (20, 13) , y_test  shape: (20,)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test = split_train_test(boston.data, boston.target)\n",
    "print(\"X_train shape: {}, y_train shape: {}\".format(X_train.shape, y_train.shape))\n",
    "print(\"X_test  shape: {} , y_test  shape: {}\".format(X_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Creating a model and training it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will create a new model. For this, find the linear regression model in sklearn and call its constructor (without parameters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model =  linear_model.LinearRegression()# TODO: create empty model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is still empty and doesn't know anything. Train (fit) it with our train-data, so that it learns things about our Boston-dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "         normalize=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: fit the train-data to the model\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Predicting test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will use our trained model to make predictions about the test-data. This means that for the given X_test values, we will ask the model what the y_values would be, based on our X_train and y_train combinations.\n",
    "\n",
    "In sklearn, the model has a function for this. Predict the y_test values with this function. We will store these values as y_pred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)  # TODO: predict y_pred from X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluating the result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have y_test (the real values for X_test) and y_pred. We can print these values and compare them, to get an idea of how good the model predicted the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19.1 20.6 15.2  7.   8.1 13.6 20.1 21.8 24.5 23.1 19.7 18.3 21.2 17.5\n",
      " 16.8 22.4 20.6 23.9 22.  11.9]\n",
      "---------------------------------------------------------------------------\n",
      "[19.52851487 21.13030683 10.69052057  6.94917077  2.25423441 12.61186689\n",
      " 14.82173569 20.44306906 20.30781014 16.40520255 13.71615353 18.97549154\n",
      " 21.14696273 18.3123007  20.36823484 23.73106449 22.649771   28.04655708\n",
      " 26.5264822  22.68372601]\n"
     ]
    }
   ],
   "source": [
    "print(y_test)\n",
    "print(\"-\"*75)  # print a line\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, it is hard to look at the numbers and decide how good the model was. We will need some kind of metric to evaluate our prediction. There are a lot of metrics we can use, so let's define two that are useful for regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1. Mean squared error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean squared error (MSE) measures the average error in our predictions. Between each point and prediction, the error is measured. These errors can be positive or negative if the prediction is below or above the actual value, so we need to take the absolute value of the error. But as we want to punish grave mistakes harder, we also square the errors. Then the average is calculated over all these squared errors. The result is one number that can be compared across different models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function that:\n",
    "* Takes y_test en y_pred as parameters.\n",
    "* Calculates the mean squared error\n",
    "* Prints the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def print_mean_squared_error():\n",
    "    # TODO: complete this function\n",
    "    \n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    \n",
    "    print(\"Mean squared error: {:.2f}\".format(mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's calculate the mean squared error for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The closer to 0.0 this value is, the better the model predicts the y_test values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2. $R^2$ score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another metric to calculate how well our model performed is the $R^2$ score. This metric is often used in linear regression. It calculates the variance of our y_pred from our y_test by taking the square of the correlation coefficient between y_pred and y_test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function that:\n",
    "* Takes y_test en y_pred as parameters.\n",
    "* Calculates the $R^2$ score.\n",
    "* Prints the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "def print_r2_score():\n",
    "    # TODO: complete this function\n",
    "    \n",
    "    r2 = \n",
    "    \n",
    "    print(\"R2 score: {:.2f}\".format(r2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we calculate the $R^2$ score for our trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If this value is 1.0, our model made a perfect prediction of the true data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3. Visualising the result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These values are easier to understand if we can visualise the data in some way.\n",
    "\n",
    "For this we write a function that visualises the actual and the predicted data. Because this function has little to do with machine learning and a lot more with Python's visualisation library Matplotlib, it is given below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def visualise_features(X_test, y_test, y_pred, column=0):\n",
    "    # we can only visualise two dimensions, so if the data has more columns, select one\n",
    "    if len(X_test) > 1:\n",
    "        X_test = X_test[:, column]\n",
    "    \n",
    "    plt.scatter(X_test, y_test, color='blue', label='True data')\n",
    "    plt.scatter(X_test, y_pred, color='orange', label='Predicted')\n",
    "    plt.xlabel(\"Features\")\n",
    "    plt.ylabel(\"Labels\")\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use this function to plot the data. To explain what we're seeing: the x-axis shows the X_test values of a certain column. The y-axis shows the y_test labels in blue and the y_pred labels in orange. So for every value on the x-axis, there will be two y-values. The orange dot should be as close to the blue dot as possible for us to have a good model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "visualise_features(X_test, y_test, y_pred, column=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at this plot, we see that the predicted values sometimes come close to the real ones, and sometimes they are completely different. What is important to notice is that our orange predicted dots all seem to follow one line (more or less). This is to be expected, as we used a linear model to predict our data. Linear models assume our data has a linear shape and try to find the best linear model for the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our prediction differs from our perfectly linear model however. The reason for this is simple: we used all the columns in the data to predict the final label. But when we visualised the data, we picked only one column for the X-axis. To demonstrate, let's train the model on just one column of our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "column = 12  # we'll only consider the data's 12th column\n",
    "X_train, y_train, X_test, y_test = split_train_test(boston.data[:, column:column+1], boston.target)\n",
    "model =   # TODO: fill this in with the model, as before\n",
    "          # TODO: train the model as before\n",
    "y_pred =  # TODO: predict y_pred as before\n",
    "visualise_features(X_test, y_test, y_pred, column=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we see our prediction is perfectly linear. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Using other models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sklearn contains a lot of models. After turning our data into a train- and test-dataset, we can apply multiple models to it. Below is a list of model names. Try to find each of them in sklearn and call the constructor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "models = {\n",
    "    \"Linear Regression\": ,  # TODO: fill in (don't forget the comma at the end)\n",
    "    \"Support Vector Machine (SVM)\": ,\n",
    "    \"Stochastic Gradient Descent (SGD) Regressor\": ,\n",
    "    \"Bayesian Ridge Regression\": ,\n",
    "    \"Lasso model with Least Angle Regression (Lars)\": ,\n",
    "    \"Automatic Relevance Determination (ARD) Regression\": ,\n",
    "    \"Passive Aggressive Regressor\": ,\n",
    "    \"Theil-Sen Regression\": \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use this list of models and apply them all to our data. If we print the names and the scores, we can compare them and find the best model for our data.\n",
    "\n",
    "As before, train the model and predict the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = split_train_test(boston.data, boston.target)\n",
    "\n",
    "for modelName, model in models.items():  # iterate over all models\n",
    "    print(modelName)\n",
    "              # TODO: train the model as before\n",
    "    y_pred =  # TODO: predict y_pred as before\n",
    "    print_mean_squared_error(y_test, y_pred)\n",
    "    print_r2_score(y_test, y_pred)\n",
    "    print(\"-\"*75)  # print a line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember, the mean squared error should be closest to 0 and the $R^2$ score closest to 1. Did one of the other models perform better than the linear regression model we used first?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
